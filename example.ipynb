{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hu and Ma (2024) Video Processing Package\n",
    "\n",
    "This example shows how to use `interactionvideo` package to process a video to study interpersonal interactions and communications. \n",
    "\n",
    "Please refer to and cite the research paper: Hu and Ma (2024), \"Persuading Investors: A Video-Based Study\", available at [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3583898), by [Allen Hu](https://www.allenanhu.com) (UBC Sauder, allen.hu@sauder.ubc.ca) and \n",
    "[Song Ma](https://songma.github.io) (Yale University and NBER, song.ma@yale.edu)\n",
    "\n",
    "**For academic research purposes only.**\n",
    "\n",
    "## Overview\n",
    "\n",
    "The video processing involves the following steps:\n",
    "1. Set up folders and check dependencies and requirements\n",
    "2. Extract images and audios from a video using [`pliers`](https://github.com/PsychoinformaticsLab/pliers)\n",
    "3. Extract text from audios using [Google Speech2Text API](https://cloud.google.com/speech-to-text)\n",
    "4. Process images (faces) using [Face++ API](https://www.faceplusplus.com/)\n",
    "5. Process text using [Loughran and McDonald (2011)](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2010.01625.x) Finance Dictionary and [Nicolas, Bai, and Fiske (2019)](https://osf.io/preprints/psyarxiv/afm8k) Social Psychology Dictionary\n",
    "6. Process audios using pre-trained ML models in [`pyAudioAnalysis`](https://github.com/tyiannak/pyAudioAnalysis) and [`speechemotionrecognition`](https://github.com/hkveeranki/speech-emotion-recognition)\n",
    "7. Aggregate information from 3V (visual, vocal, and verbal) to video level\n",
    "\n",
    "## File Structure\n",
    "\n",
    "- `example.py` and `example.ipynb`: step-by-step tutorials\n",
    "  - We recommend you start from `example.ipynb`\n",
    "- `interactionvideo`: main package folder\n",
    "- `data`: data input folder\n",
    "- `output`: output result folder\n",
    "- `mlmodel`: pre-trained ML model folder\n",
    "- `PythonSDK`: Face++ Python SDK folder, downloaded directly from [Github](https://github.com/FacePlusPlus/facepp-python-sdk)\n",
    "\n",
    "```bash\n",
    "├── interactionvideo\n",
    "│   ├── __pycache__\n",
    "│   ├── prepare.py\n",
    "│   ├── decompose.py\n",
    "│   ├── faceppml.py\n",
    "│   ├── googleml.py\n",
    "│   ├── textualanalysis.py\n",
    "│   ├── audioml.py\n",
    "│   ├── aggregate.py\n",
    "│   └── utils.py\n",
    "├── data\n",
    "│   ├── example_video.mp4\n",
    "│   └── VideoDictionary.csv\n",
    "├── mlmodel\n",
    "│   ├── pyAudioAnalysis\n",
    "│   └── speechemotionrecognition\n",
    "├── output\n",
    "│   ├── audio_temp\n",
    "│   ├── image_temp\n",
    "│   └── result_temp\n",
    "├── PythonSDK\n",
    "├── README.md\n",
    "├── requirement.txt\n",
    "├── environment.yml\n",
    "├── example.py\n",
    "└── example.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up folders and check dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "# Set the path\n",
    "RootPath = ''\n",
    "\n",
    "# Set your video file path here\n",
    "VideoFilePath = join(RootPath,'data','example_video.mp4')\n",
    "\n",
    "# Set your work path here\n",
    "# Work path is where to store meta files and output files\n",
    "WorkPath = join(RootPath,'output')\n",
    "\n",
    "# Set your path to the Google Cloud credential file here\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''\n",
    "\n",
    "# Append path to ffmpeg\n",
    "FFMPEGPath = ''\n",
    "os.environ['PATH'] += os.pathsep + FFMPEGPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decompose.py requirements satisfied.\n",
      "\n",
      "faceppml.py requirements satisfied.\n",
      "\n",
      "googleml.py requirements satisfied.\n",
      "\n",
      "audioml.py requirements satisfied.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the folders\n",
    "from interactionvideo.prepare import setup_folder\n",
    "setup_folder(WorkPath)\n",
    "\n",
    "# check the requirements for interactionvideo\n",
    "from interactionvideo.prepare import check_requirements\n",
    "check_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract images and audios from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video is 70.12 seconds long.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 702/702 [05:55<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video is sampled to 702 images.\n",
      "\n",
      "Video to images finished.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interactionvideo.decompose import convert_video_to_images\n",
    "\n",
    "# Decompose the video into a stream of images\n",
    "# The default sampling rate is 10 frames per second\n",
    "# Find the output at WorkPath\\image_temp\n",
    "convert_video_to_images(VideoFilePath, WorkPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Writing audio in E:\\Research Dropbox\\Research\\VideoProcessing\\Code\\Git Repo\\202408\\Python\\output\\audio_temp\\audio_full.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1683/1683 [00:00<00:00, 2770.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "Video to audios finished.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interactionvideo.decompose import convert_video_to_audios\n",
    "\n",
    "# Decompose the video into audios\n",
    "# Find the output at WorkPath\\audio_temp\n",
    "convert_video_to_audios(VideoFilePath, WorkPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process images (faces) using Face++ API\n",
    "\n",
    "Use Face++ ML API to process images.\n",
    "  \n",
    "Get the key and secret from https://www.faceplusplus.com. If you register at https://console.faceplusplus.com/register, use https://api-us.faceplusplus.com as the server. If you register at https://console.faceplusplus.com.cn/register, use https://api-cn.faceplusplus.com as the server. The Python SDK of Face++ is included in this repo (Python SDK). Check the orginial package at https://github.com/FacePlusPlus/facepp-python-sdk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face++ API begins. 702 images to process.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 702/702 [1:09:10<00:00,  5.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face++ API ends. 702 images processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.faceppml import process_image_by_facepp\n",
    "\n",
    "# Use Face++ ML API to process images\n",
    "# Return csv files of facial emotion, gender, predicted age\n",
    "# Find the output\n",
    "# - WorkPath\\result_temp\\face_panel_facepp.csv (full returns from Face++)\n",
    "# - WorkPath\\result_temp\\face_panel.csv (clean results)\n",
    "\n",
    "# Set your key, secret, and server here\n",
    "FaceppKey = ''\n",
    "FaceppSecret = ''\n",
    "FaceppServer = 'https://api-us.faceplusplus.com'\n",
    "\n",
    "facepp_result_df, facepp_result_clean_df = process_image_by_facepp(VideoFilePath, WorkPath,\\\n",
    "                                            FaceppKey, FaceppSecret, FaceppServer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>face_rectangle#top</th>\n",
       "      <th>face_rectangle#left</th>\n",
       "      <th>face_rectangle#width</th>\n",
       "      <th>face_rectangle#height</th>\n",
       "      <th>landmark#contour_chin#x</th>\n",
       "      <th>landmark#contour_chin#y</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes#beauty#male_score</th>\n",
       "      <th>attributes#beauty#female_score</th>\n",
       "      <th>attributes#mouthstatus#surgical_mask_or_respirator</th>\n",
       "      <th>attributes#mouthstatus#other_occlusion</th>\n",
       "      <th>attributes#mouthstatus#close</th>\n",
       "      <th>attributes#mouthstatus#open</th>\n",
       "      <th>Number of Faces</th>\n",
       "      <th>Visual-Positive</th>\n",
       "      <th>Visual-Negative</th>\n",
       "      <th>Visual-Beauty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame[0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>405</td>\n",
       "      <td>868</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>1008</td>\n",
       "      <td>654</td>\n",
       "      <td>...</td>\n",
       "      <td>41.792</td>\n",
       "      <td>44.380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.050</td>\n",
       "      <td>99.947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.26985</td>\n",
       "      <td>0.430860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame[3]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>406</td>\n",
       "      <td>867</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>1007</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>38.823</td>\n",
       "      <td>42.515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.22857</td>\n",
       "      <td>0.406690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame[6]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>404</td>\n",
       "      <td>866</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>1006</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>39.413</td>\n",
       "      <td>43.381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.32879</td>\n",
       "      <td>0.413970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame[9]</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>403</td>\n",
       "      <td>867</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>1006</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>38.357</td>\n",
       "      <td>42.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00152</td>\n",
       "      <td>0.33477</td>\n",
       "      <td>0.402910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame[12]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>401</td>\n",
       "      <td>866</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>1005</td>\n",
       "      <td>658</td>\n",
       "      <td>...</td>\n",
       "      <td>38.983</td>\n",
       "      <td>44.059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.92615</td>\n",
       "      <td>0.415210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frame[15]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>405</td>\n",
       "      <td>867</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1010</td>\n",
       "      <td>665</td>\n",
       "      <td>...</td>\n",
       "      <td>42.981</td>\n",
       "      <td>46.557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.98612</td>\n",
       "      <td>0.447690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frame[18]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>407</td>\n",
       "      <td>867</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1010</td>\n",
       "      <td>667</td>\n",
       "      <td>...</td>\n",
       "      <td>43.899</td>\n",
       "      <td>46.042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00187</td>\n",
       "      <td>0.79954</td>\n",
       "      <td>0.449705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frame[21]</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>404</td>\n",
       "      <td>869</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>1012</td>\n",
       "      <td>662</td>\n",
       "      <td>...</td>\n",
       "      <td>42.091</td>\n",
       "      <td>47.842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.09503</td>\n",
       "      <td>0.449665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frame[24]</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>403</td>\n",
       "      <td>867</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>1014</td>\n",
       "      <td>664</td>\n",
       "      <td>...</td>\n",
       "      <td>42.089</td>\n",
       "      <td>48.186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.61223</td>\n",
       "      <td>0.451375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frame[27]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>402</td>\n",
       "      <td>868</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>1014</td>\n",
       "      <td>664</td>\n",
       "      <td>...</td>\n",
       "      <td>44.724</td>\n",
       "      <td>49.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.069</td>\n",
       "      <td>99.930</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.05613</td>\n",
       "      <td>0.468775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageName  Onset  Offset  Duration  face_rectangle#top  \\\n",
       "0   frame[0]    0.0     0.1       0.1                 405   \n",
       "1   frame[3]    0.1     0.2       0.1                 406   \n",
       "2   frame[6]    0.2     0.3       0.1                 404   \n",
       "3   frame[9]    0.3     0.4       0.1                 403   \n",
       "4  frame[12]    0.4     0.5       0.1                 401   \n",
       "5  frame[15]    0.5     0.6       0.1                 405   \n",
       "6  frame[18]    0.6     0.7       0.1                 407   \n",
       "7  frame[21]    0.7     0.8       0.1                 404   \n",
       "8  frame[24]    0.8     0.9       0.1                 403   \n",
       "9  frame[27]    0.9     1.0       0.1                 402   \n",
       "\n",
       "   face_rectangle#left  face_rectangle#width  face_rectangle#height  \\\n",
       "0                  868                   249                    249   \n",
       "1                  867                   250                    250   \n",
       "2                  866                   252                    252   \n",
       "3                  867                   253                    253   \n",
       "4                  866                   258                    258   \n",
       "5                  867                   261                    261   \n",
       "6                  867                   261                    261   \n",
       "7                  869                   258                    258   \n",
       "8                  867                   262                    262   \n",
       "9                  868                   262                    262   \n",
       "\n",
       "   landmark#contour_chin#x  landmark#contour_chin#y  ...  \\\n",
       "0                     1008                      654  ...   \n",
       "1                     1007                      655  ...   \n",
       "2                     1006                      655  ...   \n",
       "3                     1006                      655  ...   \n",
       "4                     1005                      658  ...   \n",
       "5                     1010                      665  ...   \n",
       "6                     1010                      667  ...   \n",
       "7                     1012                      662  ...   \n",
       "8                     1014                      664  ...   \n",
       "9                     1014                      664  ...   \n",
       "\n",
       "   attributes#beauty#male_score  attributes#beauty#female_score  \\\n",
       "0                        41.792                          44.380   \n",
       "1                        38.823                          42.515   \n",
       "2                        39.413                          43.381   \n",
       "3                        38.357                          42.225   \n",
       "4                        38.983                          44.059   \n",
       "5                        42.981                          46.557   \n",
       "6                        43.899                          46.042   \n",
       "7                        42.091                          47.842   \n",
       "8                        42.089                          48.186   \n",
       "9                        44.724                          49.031   \n",
       "\n",
       "   attributes#mouthstatus#surgical_mask_or_respirator  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                0.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "5                                                0.0    \n",
       "6                                                0.0    \n",
       "7                                                0.0    \n",
       "8                                                0.0    \n",
       "9                                                0.0    \n",
       "\n",
       "   attributes#mouthstatus#other_occlusion  attributes#mouthstatus#close  \\\n",
       "0                                   0.003                         0.050   \n",
       "1                                   0.000                         0.000   \n",
       "2                                   0.000                         0.000   \n",
       "3                                   0.000                         0.000   \n",
       "4                                   0.000                         0.000   \n",
       "5                                   0.000                         0.000   \n",
       "6                                   0.000                         0.000   \n",
       "7                                   0.000                         0.000   \n",
       "8                                   0.003                         0.000   \n",
       "9                                   0.001                         0.069   \n",
       "\n",
       "   attributes#mouthstatus#open  Number of Faces  Visual-Positive  \\\n",
       "0                       99.947                1          0.00007   \n",
       "1                      100.000                1          0.00008   \n",
       "2                      100.000                1          0.00115   \n",
       "3                      100.000                1          0.00152   \n",
       "4                      100.000                1          0.00040   \n",
       "5                      100.000                1          0.00734   \n",
       "6                      100.000                1          0.00187   \n",
       "7                       99.999                1          0.00021   \n",
       "8                       99.996                1          0.00095   \n",
       "9                       99.930                1          0.00046   \n",
       "\n",
       "   Visual-Negative  Visual-Beauty  \n",
       "0          0.26985       0.430860  \n",
       "1          0.22857       0.406690  \n",
       "2          0.32879       0.413970  \n",
       "3          0.33477       0.402910  \n",
       "4          0.92615       0.415210  \n",
       "5          0.98612       0.447690  \n",
       "6          0.79954       0.449705  \n",
       "7          0.09503       0.449665  \n",
       "8          0.61223       0.451375  \n",
       "9          0.05613       0.468775  \n",
       "\n",
       "[10 rows x 193 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check full returns from Face++\n",
    "facepp_result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Number of Faces</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visual-Positive</th>\n",
       "      <th>Visual-Negative</th>\n",
       "      <th>Visual-Beauty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.26985</td>\n",
       "      <td>0.430860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.22857</td>\n",
       "      <td>0.406690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.32879</td>\n",
       "      <td>0.413970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00152</td>\n",
       "      <td>0.33477</td>\n",
       "      <td>0.402910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.92615</td>\n",
       "      <td>0.415210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.98612</td>\n",
       "      <td>0.447690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00187</td>\n",
       "      <td>0.79954</td>\n",
       "      <td>0.449705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.09503</td>\n",
       "      <td>0.449665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.61223</td>\n",
       "      <td>0.451375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.05613</td>\n",
       "      <td>0.468775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onset  Offset  Duration  Number of Faces Gender  Age  Visual-Positive  \\\n",
       "0    0.0     0.1       0.1                1   Male   31          0.00007   \n",
       "1    0.1     0.2       0.1                1   Male   33          0.00008   \n",
       "2    0.2     0.3       0.1                1   Male   30          0.00115   \n",
       "3    0.3     0.4       0.1                1   Male   28          0.00152   \n",
       "4    0.4     0.5       0.1                1   Male   28          0.00040   \n",
       "5    0.5     0.6       0.1                1   Male   26          0.00734   \n",
       "6    0.6     0.7       0.1                1   Male   30          0.00187   \n",
       "7    0.7     0.8       0.1                1   Male   32          0.00021   \n",
       "8    0.8     0.9       0.1                1   Male   29          0.00095   \n",
       "9    0.9     1.0       0.1                1   Male   29          0.00046   \n",
       "\n",
       "   Visual-Negative  Visual-Beauty  \n",
       "0          0.26985       0.430860  \n",
       "1          0.22857       0.406690  \n",
       "2          0.32879       0.413970  \n",
       "3          0.33477       0.402910  \n",
       "4          0.92615       0.415210  \n",
       "5          0.98612       0.447690  \n",
       "6          0.79954       0.449705  \n",
       "7          0.09503       0.449665  \n",
       "8          0.61223       0.451375  \n",
       "9          0.05613       0.468775  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check clean results\n",
    "facepp_result_clean_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract text from audios using Google Speech2Text API\n",
    "\n",
    "Set up your Google Cloud environment following\n",
    "\n",
    " - https://cloud.google.com/python\n",
    " - https://cloud.google.com/storage/docs/quickstart-console\n",
    " - https://developers.google.com/workspace/guides/create-credentials\n",
    " - https://cloud.google.com/storage/docs/creating-buckets\n",
    "\n",
    "Create a Google Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded the audio file to Google Cloud.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interactionvideo.googleml import upload_audio_to_googlecloud\n",
    "\n",
    "# Set your Google Cloud Storage bucket name here\n",
    "GoogleBucketName = ''\n",
    "\n",
    "# Upload audio file to Google Cloud Storage\n",
    "upload_audio_to_googlecloud(WorkPath, GoogleBucketName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech2Text begins. 70.12 seconds audio to process.\n",
      "\n",
      "Google Speech2Text ends. 70.12 seconds audio processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.googleml import convert_audio_to_text_by_google\n",
    "\n",
    "# Use Google Speech2Text API to convert audio to text\n",
    "# Return a txt file of full speech script and a csv file of text and punctuation\n",
    "# Find the output at \n",
    "# - WorkPath\\result_temp\\script_google.txt (full speech script)\n",
    "# - WorkPath\\result_temp\\text_panel_google.csv (text panel from Google)\n",
    "google_result_text, google_result_df = convert_audio_to_text_by_google(WorkPath, GoogleBucketName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, everyone. First of all, we will like to thank you for your interest, in our research. In this paper, we try to understand how human interaction features such as facial expressions, vocal emotions, and word choices, might influence economic agents decision-making. In order to study this question. Empirically, we build an empirical approach that uses videos of human interactions as data input, and, and machine learning based algorithms as the tool. We applied a couple approached in a setting where early stage Startup pitch, Venture capitalists, for early stage funding. We find that pitch features along visual vocal and verbal Dimensions, all matter for the probability of receiving funding. And we also show that this event impact is largely due to interaction, induced biases, rather than that interactions provide additional valuable information. The empirical structure that you see, in this code example, can hopefully help you to get started with using video in other important settings. Such as Interviews. Classroom recordings. Among many other exciting things will look forward to hearing your feedback and reading about your research. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Check full speech script from Google\n",
    "print(google_result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Sentence End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello,</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everyone.</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all,</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thank</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  Onset  Offset  Duration  Sentence End\n",
       "0     Hello,    0.4     0.6       0.2          True\n",
       "1  everyone.    0.6     1.2       0.6          True\n",
       "2      First    1.2     1.5       0.3         False\n",
       "3         of    1.5     1.5       0.0         False\n",
       "4       all,    1.5     1.9       0.4          True\n",
       "5         we    1.9     2.0       0.1         False\n",
       "6       will    2.0     2.2       0.2         False\n",
       "7       like    2.2     2.3       0.1         False\n",
       "8         to    2.3     2.4       0.1         False\n",
       "9      thank    2.4     2.7       0.3         False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check text panel from Google\n",
    "google_result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process text using LM and NBF Dictionaries\n",
    "\n",
    "Use Loughran-McDonald (2011) Finance Dictionary (LM) to construct verbal positive and negative.\n",
    "\n",
    "For more details, please check https://sraf.nd.edu/textual-analysis/resources.\n",
    "\n",
    "Use Nicolas, Bai, and Fiske (2019) Social Psychology Dictionary (NBF) to construct verbal warmth and ability.\n",
    "\n",
    "For more details, please check https://psyarxiv.com/afm8k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM and NBF Dictionaries loaded.\n",
      "\n",
      "Dictionary-based textual analysis begins. 181 words to process.\n",
      "\n",
      "Dictionary-based textual analysis ends. 181 words processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.textualanalysis import process_text_by_dict\n",
    "\n",
    "# Set LM-NBF dictionary path\n",
    "DictionaryPath = join(RootPath,'data','VideoDictionary.csv')\n",
    "\n",
    "# Dictionary-based textual analysis to get verbal measures\n",
    "# (e.g., verbal positive, negative, warmth, ability)\n",
    "# Return csv files of verbal positive, negative, warmth, and ability\n",
    "# Find the output at \n",
    "# - WorkPath\\result_temp\\text_panel.csv\n",
    "text_result_df = process_text_by_dict(WorkPath, DictionaryPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Sentence End</th>\n",
       "      <th>Verbal-Negative</th>\n",
       "      <th>Verbal-Positive</th>\n",
       "      <th>Verbal-Warmth</th>\n",
       "      <th>Verbal-Ability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello,</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everyone.</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all,</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>will</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thank</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  Onset  Offset  Duration  Sentence End  Verbal-Negative  \\\n",
       "0     Hello,    0.4     0.6       0.2          True              0.0   \n",
       "1  everyone.    0.6     1.2       0.6          True              0.0   \n",
       "2      First    1.2     1.5       0.3         False              0.0   \n",
       "3         of    1.5     1.5       0.0         False              0.0   \n",
       "4       all,    1.5     1.9       0.4          True              0.0   \n",
       "5         we    1.9     2.0       0.1         False              0.0   \n",
       "6       will    2.0     2.2       0.2         False              0.0   \n",
       "7       like    2.2     2.3       0.1         False              0.0   \n",
       "8         to    2.3     2.4       0.1         False              0.0   \n",
       "9      thank    2.4     2.7       0.3         False              0.0   \n",
       "\n",
       "   Verbal-Positive  Verbal-Warmth  Verbal-Ability  \n",
       "0              0.0            0.0             0.0  \n",
       "1              0.0            0.0             0.0  \n",
       "2              0.0            0.0             0.0  \n",
       "3              0.0            0.0             0.0  \n",
       "4              0.0            0.0             0.0  \n",
       "5              0.0            0.0             0.0  \n",
       "6              0.0            0.0             0.0  \n",
       "7              0.0            1.0             0.0  \n",
       "8              0.0            0.0             0.0  \n",
       "9              0.0            1.0             0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check text panel from Dictionary\n",
    "text_result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process audios by pre-trained ML models\n",
    "\n",
    "Construct vocal arousal and vocal valence from pre-trained SVM ML models in `pyAudioAnalysis`.\n",
    "\n",
    "The pre-trained models are located at mlmodel\\pyAudioAnalysis\n",
    "- svmSpeechEmotion_arousal\n",
    "- svmSpeechEmotion_arousalMEANS\n",
    "- svmSpeechEmotion_valence\n",
    "- svmSpeechEmotion_valenceMEANS\n",
    "\n",
    "For more details, please check https://github.com/tyiannak/pyAudioAnalysis/wiki/4.-Classification-and-Regression.\n",
    "\n",
    "Construct vocal positive and vocal negative from pre-trained LSTM ML models in `speechemotionrecognition`.\n",
    "\n",
    "The pre-trained models are located at mlmodel\\speechemotionrecognition\n",
    "- best_model_LSTM_39.h5\n",
    "\n",
    "For more details, please check https://github.com/harry-7/speech-emotion-recognition.\n",
    "\n",
    "Note: speechemotionrecognition requires tensorflow and Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyAudioAnalysis vocal emotion analysis begins. 70.12 seconds audio to process.\n",
      "\n",
      "pyAudioAnalysis ML model loaded.\n",
      "\n",
      "pyAudioAnalysis vocal emotion analysis ends. 70.12 seconds audio processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.audioml import process_audio_by_pyAudioAnalysis\n",
    "\n",
    "# Set the model path\n",
    "pyAudioAnalysisModelPath = join(RootPath,'mlmodel','pyAudioAnalysis')\n",
    "\n",
    "# Construct vocal arousal and vocal valence\n",
    "# Find the output at \n",
    "# - WorkPath\\result_temp\\audio_panel_pyAudioAnalysis.csv\n",
    "audio_result_df1 = process_audio_by_pyAudioAnalysis(WorkPath, pyAudioAnalysisModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Vocal-Arousal</th>\n",
       "      <th>Vocal-Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.12</td>\n",
       "      <td>70.12</td>\n",
       "      <td>0.404801</td>\n",
       "      <td>-0.015317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onset  Offset  Duration  Vocal-Arousal  Vocal-Valence\n",
       "0      0   70.12     70.12       0.404801      -0.015317"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check audio panel from pyAudioAnalysis\n",
    "audio_result_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechemotionrecognition vocal emotion analysis begins. 70.12 seconds audio to process.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               86016     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 90,740\n",
      "Trainable params: 90,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Software\\Anaconda3\\envs\\interactionvideo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "speechemotionrecognition ML model loaded.\n",
      "\n",
      "speechemotionrecognition vocal emotion analysis ends. 70.12 seconds audio processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.audioml import process_audio_by_speechemotionrecognition\n",
    "\n",
    "# Set the model path\n",
    "speechemotionrecognitionModelPath = join(RootPath,'mlmodel','speechemotionrecognition')\n",
    "\n",
    "# Construct vocal positive and vocal negative\n",
    "# Find the output at \n",
    "# - WorkPath\\result_temp\\audio_panel_speechemotionrecognition.csv\n",
    "audio_result_df2 = process_audio_by_speechemotionrecognition(WorkPath, speechemotionrecognitionModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Vocal-Positive</th>\n",
       "      <th>Vocal-Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.12</td>\n",
       "      <td>70.12</td>\n",
       "      <td>0.487744</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Onset  Offset  Duration  Vocal-Positive  Vocal-Negative\n",
       "0      0   70.12     70.12        0.487744          0.0068"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check audio panel from speechemotionrecognition\n",
    "audio_result_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregate information from 3V to video level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3V to video aggregation finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from interactionvideo.aggregate import aggregate_3v_to_video\n",
    "\n",
    "# Aggregate 3V information\n",
    "# Find the output at \n",
    "# - WorkPath\\result_temp\\video_panel.csv\n",
    "video_result_df = aggregate_3v_to_video(WorkPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Faces</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visual-Positive</th>\n",
       "      <td>0.014174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visual-Negative</th>\n",
       "      <td>0.44359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visual-Beauty</th>\n",
       "      <td>0.450598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocal-Positive</th>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocal-Negative</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocal-Arousal</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocal-Valence</th>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verbal-Positive</th>\n",
       "      <td>0.01105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verbal-Negative</th>\n",
       "      <td>0.005525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verbal-Warmth</th>\n",
       "      <td>0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verbal-Ability</th>\n",
       "      <td>0.038674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "Number of Faces       1.0\n",
       "Gender               Male\n",
       "Age                  32.0\n",
       "Visual-Positive  0.014174\n",
       "Visual-Negative   0.44359\n",
       "Visual-Beauty    0.450598\n",
       "Vocal-Positive       0.49\n",
       "Vocal-Negative       0.01\n",
       "Vocal-Arousal         0.4\n",
       "Vocal-Valence       -0.02\n",
       "Verbal-Positive   0.01105\n",
       "Verbal-Negative  0.005525\n",
       "Verbal-Warmth    0.033149\n",
       "Verbal-Ability   0.038674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check video panel\n",
    "video_result_df.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
